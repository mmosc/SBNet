{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T11:45:07.872079Z",
     "start_time": "2024-07-21T11:45:07.860100Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "sys.path.append(\"/home/marta/jku/SBNet/ssnet_fop\")\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "from sklearn import preprocessing\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from retrieval_model import FOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bf6e6bbe31f62c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:58:40.602788Z",
     "start_time": "2024-07-21T12:58:40.542114Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(FLAGS):\n",
    "\n",
    "    print('Split Type: %s'%(FLAGS.split_type))\n",
    "\n",
    "    if FLAGS.split_type == 'voice_only':\n",
    "        print('Reading Voice Train')\n",
    "        train_file_voice = '/share/hel/datasets/voxceleb/sbnet_feats/data/voice/voiceTrain.csv'\n",
    "        train_data = pd.read_csv(train_file_voice, header=None)\n",
    "        train_label = train_data[512]\n",
    "        # todo marta: this should be translated to multilabelbinarizer, since we have multiple labels\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train_label)\n",
    "        train_label = le.transform(train_label)\n",
    "        train_data = np.asarray(train_data)\n",
    "        train_data = train_data[:, :-1]\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    elif FLAGS.split_type == 'image_only':\n",
    "        print('Reading Face Train')\n",
    "        train_file_face = '/share/hel/datasets/voxceleb/sbnet_feats/data/face/facenetfaceTrain.csv'\n",
    "        train_data = pd.read_csv(train_file_face, header=None)\n",
    "        train_label = train_data[512]\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train_label)\n",
    "        train_label = le.transform(train_label)\n",
    "        train_data = np.asarray(train_data)\n",
    "        train_data = train_data[:, :-1]\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "\n",
    "    train_file_face = '/share/hel/datasets/voxceleb/sbnet_feats/data/face/facenetfaceTrain.csv'\n",
    "    train_file_voice = '/share/hel/datasets/voxceleb/sbnet_feats/data/voice/voiceTrain.csv'\n",
    "\n",
    "    print('Reading Train Faces')\n",
    "    img_train = pd.read_csv(train_file_face, header=None)\n",
    "    train_tmp = img_train[512]\n",
    "    img_train = np.asarray(img_train)\n",
    "    img_train = img_train[:, :-1]\n",
    "\n",
    "    train_tmp = np.asarray(train_tmp)\n",
    "    train_tmp = train_tmp.reshape((train_tmp.shape[0], 1))\n",
    "    print('Reading Train Voices')\n",
    "    voice_train = pd.read_csv(train_file_voice, header=None)\n",
    "    voice_train = np.asarray(voice_train)\n",
    "    voice_train = voice_train[:, :-1]\n",
    "\n",
    "    combined = list(zip(img_train, voice_train, train_tmp))\n",
    "    # todo marta: why do we need to shuffle here?\n",
    "    random.shuffle(combined)\n",
    "    img_train, voice_train, train_tmp = zip(*combined)\n",
    "\n",
    "    if FLAGS.split_type == 'random':\n",
    "        # todo marta: aren't we doubling the dataset, like this?\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "        combined = list(zip(train_data, train_label))\n",
    "        random.shuffle(combined)\n",
    "        train_data, train_label = zip(*combined)\n",
    "        train_data = np.asarray(train_data).astype(np.float)\n",
    "        train_label = np.asarray(train_label)\n",
    "\n",
    "    elif FLAGS.split_type == 'vfvf':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(voice_train[i])\n",
    "            train_data.append(img_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'fvfv':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(img_train[i])\n",
    "            train_data.append(voice_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'hefhev':\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    elif FLAGS.split_type == 'hevhef':\n",
    "        train_data = np.vstack((voice_train, img_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    else:\n",
    "        print('Invalid Split Type')\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_label)\n",
    "    train_label = le.transform(train_label)\n",
    "\n",
    "    # print(\"Train file length\", len(img_train))\n",
    "    # print('Shuffling\\n')\n",
    "\n",
    "    train_data = np.asarray(train_data).astype(np.float)\n",
    "    train_label = np.asarray(train_label)\n",
    "\n",
    "    return train_data, train_label\n",
    "\n",
    "def get_batch(batch_index, batch_size, labels, f_lst):\n",
    "    start_ind = batch_index * batch_size\n",
    "    end_ind = (batch_index + 1) * batch_size\n",
    "    return np.asarray(f_lst[start_ind:end_ind]), np.asarray(labels[start_ind:end_ind])\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def main(train_data, train_label):\n",
    "    \n",
    "    n_class = 901\n",
    "    model = FOP(FLAGS, train_data.shape[1], n_class)\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    opl_loss = OrthogonalProjectionLoss().cuda()\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        model.cuda()\n",
    "        ce_loss.cuda()    \n",
    "        opl_loss.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=FLAGS.lr, weight_decay=0.01)\n",
    "\n",
    "    n_parameters = sum([p.data.nelement() for p in model.parameters()])\n",
    "    print('  + Number of params: {}'.format(n_parameters))\n",
    "    \n",
    "    \n",
    "    for alpha in FLAGS.alpha_list:\n",
    "        eer_list = []\n",
    "        epoch=1\n",
    "        num_of_batches = (len(train_label) // FLAGS.batch_size)\n",
    "        loss_plot = []\n",
    "        auc_list = []\n",
    "        loss_per_epoch = 0\n",
    "        s_fac_per_epoch = 0\n",
    "        d_fac_per_epoch = 0\n",
    "        txt_dir = 'output'\n",
    "        save_dir = 'fc2_%s_%s_alpha_%0.2f'%(FLAGS.split_type, FLAGS.save_dir, alpha)\n",
    "        txt = '%s/ce_opl_%03d_%0.2f.txt'%(txt_dir, FLAGS.max_num_epoch, alpha)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        if not os.path.exists(txt_dir):\n",
    "            os.makedirs(txt_dir)\n",
    "        \n",
    "        with open(txt,'w+') as f:\n",
    "            f.write('EPOCH\\tLOSS\\tEER\\tAUC\\tS_FAC\\tD_FAC\\n')\n",
    "        \n",
    "        save_best = 'best_%s'%(save_dir)\n",
    "        \n",
    "        if not os.path.exists(save_best):\n",
    "            os.mkdir(save_best)\n",
    "        with open(txt,'a+') as f:\n",
    "            while (epoch < FLAGS.max_num_epoch):\n",
    "                print('%s\\tEpoch %03d'%(FLAGS.split_type, epoch))\n",
    "                for idx in tqdm(range(num_of_batches)):\n",
    "                    train_batch, batch_labels = get_batch(idx, FLAGS.batch_size, train_label, train_data)\n",
    "                    loss_tmp, loss_opl, loss_soft, s_fac, d_fac = train(train_batch, \n",
    "                                                                 batch_labels, \n",
    "                                                                 model, optimizer, ce_loss, opl_loss, alpha)\n",
    "                    loss_per_epoch+=loss_tmp\n",
    "                    s_fac_per_epoch+=s_fac\n",
    "                    d_fac_per_epoch+=d_fac\n",
    "                \n",
    "                loss_per_epoch/=num_of_batches\n",
    "                s_fac_per_epoch/=num_of_batches\n",
    "                d_fac_per_epoch/=num_of_batches\n",
    "                \n",
    "                loss_plot.append(loss_per_epoch)\n",
    "                if FLAGS.split_type == 'voice_only' or FLAGS.split_type == 'image_only':\n",
    "                    eer, auc = 0., 0.\n",
    "                    onlineTestSingleModality.test(FLAGS, model, test_feat)\n",
    "                else:\n",
    "                    eer, auc = online_evaluation.test(FLAGS, model, test_feat)\n",
    "                eer_list.append(eer)\n",
    "                auc_list.append(auc)\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict()}, save_dir, 'checkpoint_%04d_%0.3f.pth.tar'%(epoch, eer*100))\n",
    "\n",
    "                print('==> Epoch: %d/%d Loss: %0.2f Alpha:%0.2f, Min_EER: %0.2f'%(epoch, FLAGS.max_num_epoch, loss_per_epoch, alpha, min(eer_list)))\n",
    "                \n",
    "                if eer <= min(eer_list):\n",
    "                    min_eer = eer\n",
    "                    max_auc = auc\n",
    "                    save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict()}, save_best, 'checkpoint.pth.tar')\n",
    "            \n",
    "                f.write('%04d\\t%0.4f\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f\\n'%(epoch, loss_per_epoch, eer, auc, s_fac_per_epoch, d_fac_per_epoch))\n",
    "                loss_per_epoch = 0\n",
    "                s_fac_per_epoch = 0\n",
    "                d_fac_per_epoch = 0\n",
    "                epoch += 1\n",
    "        \n",
    "                \n",
    "        return loss_plot, min_eer, max_auc\n",
    "    \n",
    "class OrthogonalProjectionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OrthogonalProjectionLoss, self).__init__()\n",
    "        self.device = (torch.device('cuda') if FLAGS.cuda else torch.device('cpu'))\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "        labels = labels[:, None]\n",
    "\n",
    "        mask = torch.eq(labels, labels.t()).bool().to(self.device)\n",
    "        eye = torch.eye(mask.shape[0], mask.shape[1]).bool().to(self.device)\n",
    "\n",
    "        mask_pos = mask.masked_fill(eye, 0).float()\n",
    "        mask_neg = (~mask).float()\n",
    "        dot_prod = torch.matmul(features, features.t())\n",
    "\n",
    "        pos_pairs_mean = (mask_pos * dot_prod).sum() / (mask_pos.sum() + 1e-6)\n",
    "        neg_pairs_mean = torch.abs(mask_neg * dot_prod).sum() / (mask_neg.sum() + 1e-6)\n",
    "\n",
    "        loss = (1.0 - pos_pairs_mean) + (0.7 * neg_pairs_mean)\n",
    "\n",
    "        return loss, pos_pairs_mean, neg_pairs_mean\n",
    "\n",
    "\n",
    "def train(train_batch, labels, model, optimizer, ce_loss, opl_loss, alpha):\n",
    "    \n",
    "    average_loss = RunningAverage()\n",
    "    soft_losses = RunningAverage()\n",
    "    opl_losses = RunningAverage()\n",
    "\n",
    "    model.train()\n",
    "    train_batch = torch.from_numpy(train_batch).float()\n",
    "    labels = torch.from_numpy(labels)\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        train_batch, labels = train_batch.cuda(), labels.cuda()\n",
    "\n",
    "    train_batch, labels = Variable(train_batch), Variable(labels)\n",
    "    comb = model.train_forward(train_batch)\n",
    "    \n",
    "    loss_opl, s_fac, d_fac = opl_loss(comb[0], labels)\n",
    "    \n",
    "    loss_soft = ce_loss(comb[1], labels)\n",
    "    \n",
    "    loss = loss_soft + alpha * loss_opl\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    average_loss.update(loss.item())\n",
    "    opl_losses.update(loss_opl.item())\n",
    "    soft_losses.update(loss_soft.item())\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return average_loss.avg(), opl_losses.avg(), soft_losses.avg(), s_fac, d_fac\n",
    "\n",
    "class RunningAverage(object):\n",
    "    def __init__(self):\n",
    "        self.value_sum = 0.\n",
    "        self.num_items = 0. \n",
    "\n",
    "    def update(self, val):\n",
    "        self.value_sum += val \n",
    "        self.num_items += 1\n",
    "\n",
    "    def avg(self):\n",
    "        average = 0.\n",
    "        if self.num_items > 0:\n",
    "            average = self.value_sum / self.num_items\n",
    "\n",
    "        return average\n",
    " \n",
    "def save_checkpoint(state, directory, filename):\n",
    "    filename = os.path.join(directory, filename)\n",
    "    torch.save(state, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d9e30cf6e04ffbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T11:49:17.905814Z",
     "start_time": "2024-07-21T11:49:17.902023Z"
    }
   },
   "outputs": [],
   "source": [
    "global FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d40ec09aa487851f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:00:23.717955Z",
     "start_time": "2024-07-21T12:00:23.685942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--split_type'], dest='split_type', nargs=None, const=None, default='random', type=<class 'str'>, choices=None, help='split_type', metavar=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S', help='Random Seed')\n",
    "parser.add_argument('--cuda', action='store_true', default=True, help='CUDA Training')\n",
    "parser.add_argument('--save_dir', type=str, default='model', help='Directory for saving checkpoints.')\n",
    "parser.add_argument('--lr', type=float, default=1e-2, metavar='LR',\n",
    "                    help='learning rate (default: 1e-2)') \n",
    "parser.add_argument('--batch_size', type=int, default=128, help='Batch size for training.')\n",
    "parser.add_argument('--max_num_epoch', type=int, default=5, help='Max number of epochs to train, number')\n",
    "parser.add_argument('--alpha_list', type=list, default=[1], help='Alpha Values List')\n",
    "parser.add_argument('--dim_embed', type=int, default=128,\n",
    "                    help='Embedding Size')\n",
    "parser.add_argument('--split_type', type=str, default='random', help='split_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47028af40cb5fd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:00:32.327068Z",
     "start_time": "2024-07-21T12:00:32.323209Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f3516f2fc5a6e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:01:59.622989Z",
     "start_time": "2024-07-21T12:01:50.138386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Test Faces\n",
      "Reading Test Voices\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(FLAGS.seed)\n",
    "if FLAGS.cuda and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(FLAGS.seed)\n",
    "if FLAGS.split_type == 'voice_only' or FLAGS.split_type == 'face_only':\n",
    "    import onlineTestSingleModality\n",
    "    test_feat = onlineTestSingleModality.read_data(FLAGS)\n",
    "else:\n",
    "    import online_evaluation\n",
    "    test_feat = online_evaluation.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e84b804a85f8343b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:03:01.398252Z",
     "start_time": "2024-07-21T12:02:23.367355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: random\n",
      "Reading Train Faces\n",
      "Reading Train Voices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/miniconda3/envs/sbnet/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = read_data(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fec7e50cb0caa13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/miniconda3/envs/sbnet/lib/python3.6/site-packages/ipykernel_launcher.py:111: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of params: 198917\n",
      "random\tEpoch 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1723/1723 [00:09<00:00, 186.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples:  60992\n",
      "\n",
      "Evaluating\n",
      "Accuracy: 0.616+-0.030\n",
      "Area Under Curve (AUC): 0.665\n",
      "Equal Error Rate (EER): 0.379\n",
      "\n",
      "\n",
      "==> Epoch: 1/5 Loss: 7.55 Alpha:1.00, Min_EER: 0.38\n",
      "random\tEpoch 002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1723/1723 [00:08<00:00, 197.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples:  60992\n",
      "\n",
      "Evaluating\n",
      "Accuracy: 0.511+-0.015\n",
      "Area Under Curve (AUC): 0.509\n",
      "Equal Error Rate (EER): 0.493\n",
      "\n",
      "\n",
      "==> Epoch: 2/5 Loss: 7.58 Alpha:1.00, Min_EER: 0.38\n",
      "random\tEpoch 003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1723/1723 [00:09<00:00, 182.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples:  60992\n",
      "\n",
      "Evaluating\n",
      "Accuracy: 0.502+-0.007\n",
      "Area Under Curve (AUC): 0.500\n",
      "Equal Error Rate (EER): 0.500\n",
      "\n",
      "\n",
      "==> Epoch: 3/5 Loss: 7.61 Alpha:1.00, Min_EER: 0.38\n",
      "random\tEpoch 004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1723/1723 [00:09<00:00, 188.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Samples:  60992\n",
      "\n",
      "Evaluating\n",
      "Accuracy: 0.513+-0.013\n",
      "Area Under Curve (AUC): 0.515\n",
      "Equal Error Rate (EER): 0.493\n",
      "\n",
      "\n",
      "==> Epoch: 4/5 Loss: 7.61 Alpha:1.00, Min_EER: 0.38\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([7.554753468193014, 7.584764706970852, 7.613161034730722, 7.612579455295414],\n",
       " 0.37897130071855767,\n",
       " 0.6649456108484043)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e44687",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
