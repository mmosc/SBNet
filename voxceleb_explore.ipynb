{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T11:45:07.872079Z",
     "start_time": "2024-07-21T11:45:07.860100Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "sys.path.append(\"/home/marta/jku/SBNet/ssnet_fop\")\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "from sklearn import preprocessing\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from retrieval_model import FOP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "bf6e6bbe31f62c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:58:40.602788Z",
     "start_time": "2024-07-21T12:58:40.542114Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(FLAGS):\n",
    "\n",
    "    print('Split Type: %s'%(FLAGS.split_type))\n",
    "\n",
    "    if FLAGS.split_type == 'voice_only':\n",
    "        print('Reading Voice Train')\n",
    "        train_file_voice = '/share/hel/datasets/voxceleb/sbnet_feats/data/voice/voiceTrain.csv'\n",
    "        train_data = pd.read_csv(train_file_voice, header=None)\n",
    "        train_label = train_data[512]\n",
    "        # todo marta: this should be translated to multilabelbinarizer, since we have multiple labels\n",
    "        # https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.MultiLabelBinarizer.html\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train_label)\n",
    "        train_label = le.transform(train_label)\n",
    "        train_data = np.asarray(train_data)\n",
    "        train_data = train_data[:, :-1]\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    elif FLAGS.split_type == 'face_only':\n",
    "        print('Reading Face Train')\n",
    "        train_file_face = '/share/hel/datasets/voxceleb/sbnet_feats/data/face/facenetfaceTrain.csv'\n",
    "        train_data = pd.read_csv(train_file_face, header=None)\n",
    "        train_label = train_data[512]\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        le.fit(train_label)\n",
    "        train_label = le.transform(train_label)\n",
    "        train_data = np.asarray(train_data)\n",
    "        train_data = train_data[:, :-1]\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "\n",
    "    train_file_face = '/share/hel/datasets/voxceleb/sbnet_feats/data/face/facenetfaceTrain.csv'\n",
    "    train_file_voice = '/share/hel/datasets/voxceleb/sbnet_feats/data/voice/voiceTrain.csv'\n",
    "\n",
    "    print('Reading Train Faces')\n",
    "    img_train = pd.read_csv(train_file_face, header=None)\n",
    "    train_tmp = img_train[512]\n",
    "    img_train = np.asarray(img_train)\n",
    "    img_train = img_train[:, :-1]\n",
    "\n",
    "    train_tmp = np.asarray(train_tmp)\n",
    "    train_tmp = train_tmp.reshape((train_tmp.shape[0], 1))\n",
    "    print('Reading Train Voices')\n",
    "    voice_train = pd.read_csv(train_file_voice, header=None)\n",
    "    voice_train = np.asarray(voice_train)\n",
    "    voice_train = voice_train[:, :-1]\n",
    "\n",
    "    combined = list(zip(img_train, voice_train, train_tmp))\n",
    "    # todo marta: why do we need to shuffle here?\n",
    "    random.shuffle(combined)\n",
    "    img_train, voice_train, train_tmp = zip(*combined)\n",
    "\n",
    "    if FLAGS.split_type == 'random':\n",
    "        # todo marta: aren't we doubling the dataset, like this?\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "        combined = list(zip(train_data, train_label))\n",
    "        random.shuffle(combined)\n",
    "        train_data, train_label = zip(*combined)\n",
    "        train_data = np.asarray(train_data).astype(np.float)\n",
    "        train_label = np.asarray(train_label)\n",
    "\n",
    "    elif FLAGS.split_type == 'vfvf':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(voice_train[i])\n",
    "            train_data.append(img_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'fvfv':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(img_train[i])\n",
    "            train_data.append(voice_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'hefhev':\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    elif FLAGS.split_type == 'hevhef':\n",
    "        train_data = np.vstack((voice_train, img_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    else:\n",
    "        print('Invalid Split Type')\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_label)\n",
    "    train_label = le.transform(train_label)\n",
    "\n",
    "    # print(\"Train file length\", len(img_train))\n",
    "    # print('Shuffling\\n')\n",
    "\n",
    "    train_data = np.asarray(train_data).astype(np.float)\n",
    "    train_label = np.asarray(train_label)\n",
    "\n",
    "    return train_data, train_label\n",
    "\n",
    "def get_batch(batch_index, batch_size, labels, f_lst):\n",
    "    start_ind = batch_index * batch_size\n",
    "    end_ind = (batch_index + 1) * batch_size\n",
    "    return np.asarray(f_lst[start_ind:end_ind]), np.asarray(labels[start_ind:end_ind])\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def main(train_data, train_label):\n",
    "    \n",
    "    n_class = 901\n",
    "    model = FOP(FLAGS, train_data.shape[1], n_class)\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    opl_loss = OrthogonalProjectionLoss().cuda()\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        model.cuda()\n",
    "        ce_loss.cuda()    \n",
    "        opl_loss.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=FLAGS.lr, weight_decay=0.01)\n",
    "\n",
    "    n_parameters = sum([p.data.nelement() for p in model.parameters()])\n",
    "    print('  + Number of params: {}'.format(n_parameters))\n",
    "    \n",
    "    \n",
    "    for alpha in FLAGS.alpha_list:\n",
    "        eer_list = []\n",
    "        epoch=1\n",
    "        num_of_batches = (len(train_label) // FLAGS.batch_size)\n",
    "        loss_plot = []\n",
    "        auc_list = []\n",
    "        loss_per_epoch = 0\n",
    "        s_fac_per_epoch = 0\n",
    "        d_fac_per_epoch = 0\n",
    "        txt_dir = 'output'\n",
    "        save_dir = 'fc2_%s_%s_alpha_%0.2f'%(FLAGS.split_type, FLAGS.save_dir, alpha)\n",
    "        txt = '%s/ce_opl_%03d_%0.2f.txt'%(txt_dir, FLAGS.max_num_epoch, alpha)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        if not os.path.exists(txt_dir):\n",
    "            os.makedirs(txt_dir)\n",
    "        \n",
    "        with open(txt,'w+') as f:\n",
    "            f.write('EPOCH\\tLOSS\\tEER\\tAUC\\tS_FAC\\tD_FAC\\n')\n",
    "        \n",
    "        save_best = 'best_%s'%(save_dir)\n",
    "        \n",
    "        if not os.path.exists(save_best):\n",
    "            os.mkdir(save_best)\n",
    "        with open(txt,'a+') as f:\n",
    "            while (epoch < FLAGS.max_num_epoch):\n",
    "                print('%s\\tEpoch %03d'%(FLAGS.split_type, epoch))\n",
    "                for idx in tqdm(range(num_of_batches)):\n",
    "                    train_batch, batch_labels = get_batch(idx, FLAGS.batch_size, train_label, train_data)\n",
    "                    # voice_feats, _ = get_batch(idx, FLAGS.batch_size, train_label, voice_train)\n",
    "                    loss_tmp, loss_opl, loss_soft, s_fac, d_fac = train(train_batch, \n",
    "                                                                 batch_labels, \n",
    "                                                                 model, optimizer, ce_loss, opl_loss, alpha)\n",
    "                    loss_per_epoch+=loss_tmp\n",
    "                    s_fac_per_epoch+=s_fac\n",
    "                    d_fac_per_epoch+=d_fac\n",
    "                \n",
    "                loss_per_epoch/=num_of_batches\n",
    "                s_fac_per_epoch/=num_of_batches\n",
    "                d_fac_per_epoch/=num_of_batches\n",
    "                \n",
    "                loss_plot.append(loss_per_epoch)\n",
    "                if FLAGS.split_type == 'voice_only' or FLAGS.split_type == 'face_only':\n",
    "                    eer, auc = onlineTestSingleModality.test(FLAGS, model, test_feat)\n",
    "                else:\n",
    "                    eer, auc = online_evaluation.test(FLAGS, model, test_feat)\n",
    "                eer_list.append(eer)\n",
    "                auc_list.append(auc)\n",
    "                save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict()}, save_dir, 'checkpoint_%04d_%0.3f.pth.tar'%(epoch, eer*100))\n",
    "\n",
    "                print('==> Epoch: %d/%d Loss: %0.2f Alpha:%0.2f, Min_EER: %0.2f'%(epoch, FLAGS.max_num_epoch, loss_per_epoch, alpha, min(eer_list)))\n",
    "                \n",
    "                if eer <= min(eer_list):\n",
    "                    min_eer = eer\n",
    "                    max_auc = auc\n",
    "                    save_checkpoint({\n",
    "                    'epoch': epoch,\n",
    "                    'state_dict': model.state_dict()}, save_best, 'checkpoint.pth.tar')\n",
    "            \n",
    "                f.write('%04d\\t%0.4f\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f\\n'%(epoch, loss_per_epoch, eer, auc, s_fac_per_epoch, d_fac_per_epoch))\n",
    "                loss_per_epoch = 0\n",
    "                s_fac_per_epoch = 0\n",
    "                d_fac_per_epoch = 0\n",
    "                epoch += 1\n",
    "        \n",
    "                \n",
    "        return loss_plot, min_eer, max_auc\n",
    "    \n",
    "class OrthogonalProjectionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OrthogonalProjectionLoss, self).__init__()\n",
    "        self.device = (torch.device('cuda') if FLAGS.cuda else torch.device('cpu'))\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "        labels = labels[:, None]\n",
    "\n",
    "        mask = torch.eq(labels, labels.t()).bool().to(self.device)\n",
    "        eye = torch.eye(mask.shape[0], mask.shape[1]).bool().to(self.device)\n",
    "\n",
    "        mask_pos = mask.masked_fill(eye, 0).float()\n",
    "        mask_neg = (~mask).float()\n",
    "        dot_prod = torch.matmul(features, features.t())\n",
    "\n",
    "        pos_pairs_mean = (mask_pos * dot_prod).sum() / (mask_pos.sum() + 1e-6)\n",
    "        neg_pairs_mean = torch.abs(mask_neg * dot_prod).sum() / (mask_neg.sum() + 1e-6)\n",
    "\n",
    "        loss = (1.0 - pos_pairs_mean) + (0.7 * neg_pairs_mean)\n",
    "\n",
    "        return loss, pos_pairs_mean, neg_pairs_mean\n",
    "\n",
    "\n",
    "def train(train_batch, labels, model, optimizer, ce_loss, opl_loss, alpha):\n",
    "    \n",
    "    average_loss = RunningAverage()\n",
    "    soft_losses = RunningAverage()\n",
    "    opl_losses = RunningAverage()\n",
    "\n",
    "    model.train()\n",
    "    # face_feats = torch.from_numpy(face_feats).float()\n",
    "    train_batch = torch.from_numpy(train_batch).float()\n",
    "    labels = torch.from_numpy(labels)\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        train_batch, labels = train_batch.cuda(), labels.cuda()\n",
    "\n",
    "    train_batch, labels = Variable(train_batch), Variable(labels)\n",
    "    comb = model.train_forward(train_batch)\n",
    "    \n",
    "    loss_opl, s_fac, d_fac = opl_loss(comb[0], labels)\n",
    "    \n",
    "    loss_soft = ce_loss(comb[1], labels)\n",
    "    \n",
    "    loss = loss_soft + alpha * loss_opl\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    average_loss.update(loss.item())\n",
    "    opl_losses.update(loss_opl.item())\n",
    "    soft_losses.update(loss_soft.item())\n",
    "    \n",
    "    optimizer.step()\n",
    "\n",
    "    return average_loss.avg(), opl_losses.avg(), soft_losses.avg(), s_fac, d_fac\n",
    "\n",
    "class RunningAverage(object):\n",
    "    def __init__(self):\n",
    "        self.value_sum = 0.\n",
    "        self.num_items = 0. \n",
    "\n",
    "    def update(self, val):\n",
    "        self.value_sum += val \n",
    "        self.num_items += 1\n",
    "\n",
    "    def avg(self):\n",
    "        average = 0.\n",
    "        if self.num_items > 0:\n",
    "            average = self.value_sum / self.num_items\n",
    "\n",
    "        return average\n",
    " \n",
    "def save_checkpoint(state, directory, filename):\n",
    "    filename = os.path.join(directory, filename)\n",
    "    torch.save(state, filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9e30cf6e04ffbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T11:49:17.905814Z",
     "start_time": "2024-07-21T11:49:17.902023Z"
    }
   },
   "outputs": [],
   "source": [
    "global FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d40ec09aa487851f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:00:23.717955Z",
     "start_time": "2024-07-21T12:00:23.685942Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--split_type'], dest='split_type', nargs=None, const=None, default='hefhev', type=<class 'str'>, choices=None, help='split_type', metavar=None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S', help='Random Seed')\n",
    "parser.add_argument('--cuda', action='store_true', default=True, help='CUDA Training')\n",
    "parser.add_argument('--save_dir', type=str, default='model', help='Directory for saving checkpoints.')\n",
    "parser.add_argument('--lr', type=float, default=1e-2, metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)') \n",
    "parser.add_argument('--batch_size', type=int, default=128, help='Batch size for training.')\n",
    "parser.add_argument('--max_num_epoch', type=int, default=5, help='Max number of epochs to train, number')\n",
    "parser.add_argument('--alpha_list', type=list, default=[1], help='Alpha Values List')\n",
    "parser.add_argument('--dim_embed', type=int, default=128,\n",
    "                    help='Embedding Size')\n",
    "parser.add_argument('--split_type', type=str, default='hefhev', help='split_type')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47028af40cb5fd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:00:32.327068Z",
     "start_time": "2024-07-21T12:00:32.323209Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS, unparsed = parser.parse_known_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70f3516f2fc5a6e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:01:59.622989Z",
     "start_time": "2024-07-21T12:01:50.138386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Test Faces\n",
      "Reading Test Voices\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(FLAGS.seed)\n",
    "if FLAGS.cuda and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(FLAGS.seed)\n",
    "if FLAGS.split_type == 'voice_only' or FLAGS.split_type == 'face_only':\n",
    "    import onlineTestSingleModality\n",
    "    test_feat = onlineTestSingleModality.read_data(FLAGS)\n",
    "else:\n",
    "    import online_evaluation\n",
    "    test_feat = online_evaluation.read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e84b804a85f8343b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:03:01.398252Z",
     "start_time": "2024-07-21T12:02:23.367355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: hefhev\n",
      "Reading Train Faces\n",
      "Reading Train Voices\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/utils/validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train file length 110281\n",
      "Shuffling\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = read_data(FLAGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd90c488685380b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:06:19.504864Z",
     "start_time": "2024-07-21T12:06:19.499826Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: hefhev\n"
     ]
    }
   ],
   "source": [
    "print('Split Type: %s'%(FLAGS.split_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e9eeee111e0b85f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:22:28.986368Z",
     "start_time": "2024-07-21T12:22:11.058182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Train Faces\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "\n",
    "train_file_face = '/home/marta/jku/SBNet/data/face/facenetfaceTrain.csv'\n",
    "train_file_voice = '/home/marta/jku/SBNet/data/voice/voiceTrain.csv'\n",
    "\n",
    "print('Reading Train Faces')\n",
    "img_train = pd.read_csv(train_file_face, header=None)\n",
    "# each row is an instance, each column is a feature component. The last column is the label\n",
    "train_tmp = img_train[512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "103b3fa04984428b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:22:29.037909Z",
     "start_time": "2024-07-21T12:22:28.988011Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 110281 entries, 0 to 110280\n",
      "Columns: 513 entries, 0 to 512\n",
      "dtypes: float64(513)\n",
      "memory usage: 431.6 MB\n"
     ]
    }
   ],
   "source": [
    "img_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6561442ddc9b75bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:28:40.435461Z",
     "start_time": "2024-07-21T12:28:40.405990Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "      <th>512</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.041904</td>\n",
       "      <td>0.018898</td>\n",
       "      <td>-0.036847</td>\n",
       "      <td>0.014325</td>\n",
       "      <td>0.027192</td>\n",
       "      <td>-0.038393</td>\n",
       "      <td>-0.019792</td>\n",
       "      <td>0.126404</td>\n",
       "      <td>0.036059</td>\n",
       "      <td>0.010294</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.011719</td>\n",
       "      <td>-0.031156</td>\n",
       "      <td>0.060002</td>\n",
       "      <td>-0.006154</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.014394</td>\n",
       "      <td>-0.064254</td>\n",
       "      <td>-0.033389</td>\n",
       "      <td>-0.047423</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 513 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.041904  0.018898 -0.036847  0.014325  0.027192 -0.038393 -0.019792   \n",
       "\n",
       "        7         8         9    ...       503       504       505       506  \\\n",
       "0  0.126404  0.036059  0.010294  ... -0.011719 -0.031156  0.060002 -0.006154   \n",
       "\n",
       "     507       508       509       510       511  512  \n",
       "0  0.042  0.014394 -0.064254 -0.033389 -0.047423  0.0  \n",
       "\n",
       "[1 rows x 513 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d519f552eb60f33b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:33:29.534528Z",
     "start_time": "2024-07-21T12:33:29.523053Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "img_train = np.asarray(img_train)\n",
    "img_train = img_train[:, :-1]\n",
    "\n",
    "train_tmp = np.asarray(train_tmp)\n",
    "train_tmp = train_tmp.reshape((train_tmp.shape[0], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6bbf460932843c0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:18:48.919964Z",
     "start_time": "2024-07-21T12:18:18.296453Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading Train Faces\n",
      "Reading Train Voices\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print('Reading Train Voices')\n",
    "voice_train = pd.read_csv(train_file_voice, header=None)\n",
    "voice_train = np.asarray(voice_train)\n",
    "# in this case we don't need the labels from voice_train since we already have them from face_train\n",
    "voice_train = voice_train[:, :-1]\n",
    "\n",
    "combined = list(zip(img_train, voice_train, train_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ba2e8155b5897111",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:31:19.217465Z",
     "start_time": "2024-07-21T12:31:19.211111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 512, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined[0][0]), len(combined[0][1]), len(combined[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "784ccc2421d2e7b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:34:52.361874Z",
     "start_time": "2024-07-21T12:34:52.355017Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04190374,  0.01889801, -0.03684678, ..., -0.0642544 ,\n",
       "        -0.03338936, -0.04742257],\n",
       "       [ 0.01741058,  0.05221307, -0.01278405, ..., -0.05190615,\n",
       "         0.00989682, -0.07288535],\n",
       "       [ 0.02766443,  0.00860543, -0.01457   , ..., -0.03756009,\n",
       "        -0.01697322, -0.05725462],\n",
       "       ...,\n",
       "       [-0.01778129,  0.03377941, -0.0039551 , ..., -0.04349498,\n",
       "         0.0620859 , -0.09389633],\n",
       "       [ 0.04519489,  0.00646739, -0.05553465, ...,  0.01645009,\n",
       "        -0.01502666, -0.07869098],\n",
       "       [ 0.00147089, -0.00020251, -0.04145969, ..., -0.03603435,\n",
       "        -0.02638473, -0.0857068 ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86557f033ec225b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo marta: why do we need to shuffle here? --> because labels are ordered! so the same people will appear in the top, and the same in the bottom\n",
    "random.shuffle(combined)\n",
    "img_train, voice_train, train_tmp = zip(*combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9da60093b33c6d35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:34:59.002382Z",
     "start_time": "2024-07-21T12:34:58.987051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04190374,  0.01889801, -0.03684678, ..., -0.0642544 ,\n",
       "        -0.03338936, -0.04742257],\n",
       "       [ 0.01741058,  0.05221307, -0.01278405, ..., -0.05190615,\n",
       "         0.00989682, -0.07288535],\n",
       "       [ 0.02766443,  0.00860543, -0.01457   , ..., -0.03756009,\n",
       "        -0.01697322, -0.05725462],\n",
       "       ...,\n",
       "       [-0.01778129,  0.03377941, -0.0039551 , ..., -0.04349498,\n",
       "         0.0620859 , -0.09389633],\n",
       "       [ 0.04519489,  0.00646739, -0.05553465, ...,  0.01645009,\n",
       "        -0.01502666, -0.07869098],\n",
       "       [ 0.00147089, -0.00020251, -0.04145969, ..., -0.03603435,\n",
       "        -0.02638473, -0.0857068 ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f6e851bbea57de09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:38:05.923339Z",
     "start_time": "2024-07-21T12:38:05.089765Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data = np.vstack((voice_train, img_train))\n",
    "train_label = np.vstack((train_tmp, train_tmp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d62ea0a4ae17402f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:58:57.542468Z",
     "start_time": "2024-07-21T12:58:57.538808Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS.split_type = 'hefhev'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b2fdb31ce909ad49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:59:25.622566Z",
     "start_time": "2024-07-21T12:58:57.940317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: hefhev\n",
      "Reading Train Faces\n",
      "Reading Train Voices\n",
      "(220562, 512)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = read_data(FLAGS)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7f16f0e7af3878b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:59:25.629946Z",
     "start_time": "2024-07-21T12:59:25.625069Z"
    }
   },
   "outputs": [],
   "source": [
    "FLAGS.split_type = 'voice_only'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "89c6ea242d695b1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-21T12:59:35.667123Z",
     "start_time": "2024-07-21T12:59:25.632734Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: voice_only\n",
      "Reading Voice Train\n",
      "(110281, 512)\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label = read_data(FLAGS)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d259e2843fe7f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if FLAGS.split_type == 'random':\n",
    "    # todo marta: aren't we doubling the dataset, like this?\n",
    "    train_data = np.vstack((img_train, voice_train))\n",
    "    train_label = np.vstack((train_tmp, train_tmp))\n",
    "    combined = list(zip(train_data, train_label))\n",
    "    random.shuffle(combined)\n",
    "    train_data, train_label = zip(*combined)\n",
    "    train_data = np.asarray(train_data).astype(np.float)\n",
    "    train_label = np.asarray(train_label)\n",
    "\n",
    "elif FLAGS.split_type == 'vfvf':\n",
    "    for i in range(len(voice_train)):\n",
    "        train_data.append(voice_train[i])\n",
    "        train_data.append(img_train[i])\n",
    "        train_label.append(train_tmp[i])\n",
    "        train_label.append(train_tmp[i])\n",
    "\n",
    "elif FLAGS.split_type == 'fvfv':\n",
    "    for i in range(len(voice_train)):\n",
    "        train_data.append(img_train[i])\n",
    "        train_data.append(voice_train[i])\n",
    "        train_label.append(train_tmp[i])\n",
    "        train_label.append(train_tmp[i])\n",
    "\n",
    "elif FLAGS.split_type == 'hefhev':\n",
    "    train_data = np.vstack((img_train, voice_train))\n",
    "    train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "\n",
    "else:\n",
    "    print('Invalid Split Type')\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(train_label)\n",
    "train_label = le.transform(train_label)\n",
    "\n",
    "print(\"Train file length\", len(img_train))\n",
    "print('Shuffling\\n')\n",
    "\n",
    "train_data = np.asarray(train_data).astype(np.float)\n",
    "train_label = np.asarray(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec7e50cb0caa13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "main(train_data, train_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
