{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:09.876283Z",
     "start_time": "2024-07-26T12:20:08.062161Z"
    }
   },
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable\n",
    "import torch.backends.cudnn as cudnn\n",
    "import sys\n",
    "sys.path.append(\"/home/marta/jku/SBNet/ssnet_fop\")\n",
    "\n",
    "import pandas as pd\n",
    "from scipy import random\n",
    "from sklearn import preprocessing\n",
    "# import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from retrieval_model import FOP\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:10.492033Z",
     "start_time": "2024-07-26T12:20:10.417258Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cuda.is_available()",
   "id": "4184629c9d49e195",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "df4d5a2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:15.774841Z",
     "start_time": "2024-07-26T12:20:15.771363Z"
    }
   },
   "source": "data_folder = '/home/marta/jku/LLaVA/mmimdb'",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "fd8d2c98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:16.510180Z",
     "start_time": "2024-07-26T12:20:16.502538Z"
    }
   },
   "source": [
    "texts_folder = os.path.join(data_folder, 'llava_encoded_texts')\n",
    "\n",
    "train_text_df = os.path.join(texts_folder, 'llava_plot_first_latent_train.csv')\n",
    "test_text_df = os.path.join(texts_folder, 'llava_plot_first_latent_test.csv')\n",
    "\n",
    "images_folder = os.path.join(data_folder, 'llava_encoded_images')\n",
    "\n",
    "train_image_df = os.path.join(images_folder, 'llava_images_latent_train.csv')\n",
    "test_image_df = os.path.join(images_folder, 'llava_images_latent_test.csv')\n",
    "\n",
    "labels = ['action', 'adult', 'adventure', 'animation', 'biography', 'comedy',\n",
    "       'crime', 'documentary', 'drama', 'family', 'fantasy', 'film-noir',\n",
    "       'history', 'horror', 'music', 'musical', 'mystery', 'news',\n",
    "       'reality-tv', 'romance', 'sci-fi', 'short', 'sport', 'talk-show',\n",
    "       'thriller', 'war', 'western']"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:17:29.684963Z",
     "start_time": "2024-07-26T12:17:29.679240Z"
    }
   },
   "cell_type": "code",
   "source": "images_folder",
   "id": "d0d16f975de6dff2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/marta/jku/LLaVA/mmimdb/llava_encoded_images'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e8f434be",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:27.385094Z",
     "start_time": "2024-07-26T12:20:27.378240Z"
    }
   },
   "source": [
    "def sigmoid(x):\n",
    "   return 1. / (1. + np.exp(-x))"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "bf6e6bbe31f62c6d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:31.728320Z",
     "start_time": "2024-07-26T12:20:31.646165Z"
    }
   },
   "source": [
    "def read_data(FLAGS):\n",
    "\n",
    "    print('Split Type: %s'%(FLAGS.split_type))\n",
    "\n",
    "    if FLAGS.split_type == 'text_only':\n",
    "        print('Reading Text Train')\n",
    "        train_file_text = train_text_df\n",
    "        train_data = pd.read_csv(train_file_text, index_col='item_id')\n",
    "        train_label = train_data[labels]\n",
    "        train_data = train_data.drop(columns=labels)\n",
    "        train_data = np.asarray(train_data)\n",
    "        # Shuffle the data also if only one modality is used\n",
    "        combined = list(zip(train_data, train_label))\n",
    "        random.shuffle(combined)\n",
    "        train_data, train_label = zip(*combined)\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    elif FLAGS.split_type == 'image_only':\n",
    "        print('Reading Image Train')\n",
    "        train_file_image = train_image_df\n",
    "        train_data = pd.read_csv(train_file_image, index_col='item_id')\n",
    "        train_label = train_data[labels]\n",
    "        train_data = train_data.drop(columns=labels)\n",
    "        train_data = np.asarray(train_data)\n",
    "        # Shuffle the data also if only one modality is used\n",
    "        combined = list(zip(train_data, train_label))\n",
    "        random.shuffle(combined)\n",
    "        train_data, train_label = zip(*combined)\n",
    "\n",
    "        return train_data, train_label\n",
    "\n",
    "    train_data = []\n",
    "    train_label = []\n",
    "\n",
    "    train_file_face = '/share/hel/datasets/voxceleb/sbnet_feats/data/face/facenetfaceTrain.csv'\n",
    "    train_file_voice = '/share/hel/datasets/voxceleb/sbnet_feats/data/voice/voiceTrain.csv'\n",
    "\n",
    "    print('Reading Train Faces')\n",
    "    img_train = pd.read_csv(train_file_face, header=None)\n",
    "    train_tmp = img_train[512]\n",
    "    img_train = np.asarray(img_train)\n",
    "    img_train = img_train[:, :-1]\n",
    "\n",
    "    train_tmp = np.asarray(train_tmp)\n",
    "    train_tmp = train_tmp.reshape((train_tmp.shape[0], 1))\n",
    "    print('Reading Train Voices')\n",
    "    voice_train = pd.read_csv(train_file_voice, header=None)\n",
    "    voice_train = np.asarray(voice_train)\n",
    "    voice_train = voice_train[:, :-1]\n",
    "\n",
    "    combined = list(zip(img_train, voice_train, train_tmp))\n",
    "    # todo marta: why do we need to shuffle here?\n",
    "    random.shuffle(combined)\n",
    "    img_train, voice_train, train_tmp = zip(*combined)\n",
    "\n",
    "    if FLAGS.split_type == 'random':\n",
    "        # todo marta: aren't we doubling the dataset, like this?\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "        combined = list(zip(train_data, train_label))\n",
    "        random.shuffle(combined)\n",
    "        train_data, train_label = zip(*combined)\n",
    "        train_data = np.asarray(train_data).astype(np.float)\n",
    "        train_label = np.asarray(train_label)\n",
    "\n",
    "    elif FLAGS.split_type == 'vfvf':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(voice_train[i])\n",
    "            train_data.append(img_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'fvfv':\n",
    "        for i in range(len(voice_train)):\n",
    "            train_data.append(img_train[i])\n",
    "            train_data.append(voice_train[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "            train_label.append(train_tmp[i])\n",
    "\n",
    "    elif FLAGS.split_type == 'hefhev':\n",
    "        train_data = np.vstack((img_train, voice_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    elif FLAGS.split_type == 'hevhef':\n",
    "        train_data = np.vstack((voice_train, img_train))\n",
    "        train_label = np.vstack((train_tmp, train_tmp))\n",
    "\n",
    "    else:\n",
    "        print('Invalid Split Type')\n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    le.fit(train_label)\n",
    "    train_label = le.transform(train_label)\n",
    "\n",
    "    # print(\"Train file length\", len(img_train))\n",
    "    # print('Shuffling\\n')\n",
    "\n",
    "    train_data = np.asarray(train_data).astype(np.float)\n",
    "    train_label = np.asarray(train_label)\n",
    "\n",
    "    return train_data, train_label\n",
    "\n",
    "def get_batch(batch_index, batch_size, labels, f_lst):\n",
    "    start_ind = batch_index * batch_size\n",
    "    end_ind = (batch_index + 1) * batch_size\n",
    "    return np.asarray(f_lst[start_ind:end_ind]), np.asarray(labels[start_ind:end_ind])\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)\n",
    "\n",
    "def main(train_data, train_label):\n",
    "    n_class = train_label.shape[1]\n",
    "    model = FOP(FLAGS, train_data.shape[1], n_class)\n",
    "    model.apply(init_weights)\n",
    "    \n",
    "    # ce_loss = nn.CrossEntropyLoss().cuda()\n",
    "    bce_logits_loss = nn.BCEWithLogitsLoss()\n",
    "    # We do not necessarily want orthogonal projection loss imo\n",
    "    # opl_loss = OrthogonalProjectionLoss().cuda()\n",
    "    opl_loss = None\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        model.cuda()\n",
    "        # ce_loss.cuda()    \n",
    "        bce_logits_loss.cuda()\n",
    "        if opl_loss:\n",
    "            opl_loss.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=FLAGS.lr, weight_decay=0.01)\n",
    "\n",
    "    n_parameters = sum([p.data.nelement() for p in model.parameters()])\n",
    "    print('  + Number of params: {}'.format(n_parameters))\n",
    "    \n",
    "    \n",
    "    for alpha in FLAGS.alpha_list:\n",
    "        epoch = 1\n",
    "        num_of_batches = (len(train_label) // FLAGS.batch_size)\n",
    "        loss_plot = []\n",
    "        precision_list = []\n",
    "        recall_list = []\n",
    "        loss_per_epoch = 0\n",
    "        s_fac_per_epoch = 0\n",
    "        d_fac_per_epoch = 0\n",
    "        txt_dir = 'output'\n",
    "        save_dir = 'fc2_%s_%s_alpha_%0.2f'%(FLAGS.split_type, FLAGS.save_dir, alpha)\n",
    "        txt = '%s/ce_opl_%03d_%0.2f.txt'%(txt_dir, FLAGS.max_num_epoch, alpha)\n",
    "        \n",
    "        if not os.path.exists(save_dir):\n",
    "            os.makedirs(save_dir)\n",
    "        \n",
    "        if not os.path.exists(txt_dir):\n",
    "            os.makedirs(txt_dir)\n",
    "        \n",
    "        with open(txt,'w+') as f:\n",
    "            f.write('EPOCH\\tLOSS\\tprecision\\trecall\\tS_FAC\\tD_FAC\\n')\n",
    "        \n",
    "        save_best = 'best_%s'%(save_dir)\n",
    "        \n",
    "        if not os.path.exists(save_best):\n",
    "            os.mkdir(save_best)\n",
    "        with open(txt,'a+') as f:\n",
    "            while (epoch < FLAGS.max_num_epoch):\n",
    "                print('%s\\tEpoch %03d'%(FLAGS.split_type, epoch))\n",
    "                for idx in tqdm(range(num_of_batches)):\n",
    "                    train_batch, batch_labels = get_batch(idx, FLAGS.batch_size, train_label, train_data)\n",
    "                    # voice_feats, _ = get_batch(idx, FLAGS.batch_size, train_label, voice_train)\n",
    "                    loss_tmp, loss_opl, loss_soft, s_fac, d_fac = train(train_batch, \n",
    "                                                                 batch_labels, \n",
    "                                                                 model, optimizer, bce_logits_loss, opl_loss, alpha)\n",
    "                    loss_per_epoch+=loss_tmp\n",
    "                    s_fac_per_epoch+=s_fac\n",
    "                    d_fac_per_epoch+=d_fac\n",
    "                \n",
    "                loss_per_epoch/=num_of_batches\n",
    "                s_fac_per_epoch/=num_of_batches\n",
    "                d_fac_per_epoch/=num_of_batches\n",
    "                \n",
    "                loss_plot.append(loss_per_epoch)\n",
    "                # ToDo\n",
    "                \n",
    "                # if FLAGS.split_type == 'voice_only' or FLAGS.split_type == 'face_only':\n",
    "                #     eer, auc = onlineTestSingleModality.test(FLAGS, model, test_feat)\n",
    "                # else:\n",
    "                #     eer, auc = online_evaluation.test(FLAGS, model, test_feat)\n",
    "                # eer_list.append(eer)\n",
    "                # auc_list.append(auc)\n",
    "                # save_checkpoint({\n",
    "                #    'epoch': epoch,\n",
    "                #    'state_dict': model.state_dict()}, save_dir, 'checkpoint_%04d_%0.3f.pth.tar'%(epoch, eer*100))\n",
    "\n",
    "#                 print('==> Epoch: %d/%d Loss: %0.2f Alpha:%0.2f, Min_EER: %0.2f'%(epoch, FLAGS.max_num_epoch, loss_per_epoch, alpha, min(eer_list)))\n",
    "                \n",
    "#                 if eer <= min(eer_list):\n",
    "#                     min_eer = eer\n",
    "#                     max_auc = auc\n",
    "#                     save_checkpoint({\n",
    "#                     'epoch': epoch,\n",
    "#                     'state_dict': model.state_dict()}, save_best, 'checkpoint.pth.tar')\n",
    "                # ToDo \n",
    "                eer, auc = 0., 0.\n",
    "                f.write('%04d\\t%0.4f\\t%0.2f\\t%0.2f\\t%0.2f\\t%0.2f\\n'%(epoch, loss_per_epoch, eer, auc, s_fac_per_epoch, d_fac_per_epoch))\n",
    "                loss_per_epoch = 0\n",
    "                s_fac_per_epoch = 0\n",
    "                d_fac_per_epoch = 0\n",
    "                epoch += 1\n",
    "        \n",
    "        return loss_plot# , min_eer, max_auc                \n",
    "#         return loss_plot, min_eer, max_auc\n",
    "    \n",
    "    \n",
    "class OrthogonalProjectionLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(OrthogonalProjectionLoss, self).__init__()\n",
    "        self.device = (torch.device('cuda') if FLAGS.cuda else torch.device('cpu'))\n",
    "\n",
    "    def forward(self, features, labels=None):\n",
    "        \n",
    "        features = F.normalize(features, p=2, dim=1)\n",
    "\n",
    "        labels = labels[:, None]\n",
    "\n",
    "        mask = torch.eq(labels, labels.t()).bool().to(self.device)\n",
    "        eye = torch.eye(mask.shape[0], mask.shape[1]).bool().to(self.device)\n",
    "\n",
    "        mask_pos = mask.masked_fill(eye, 0).float()\n",
    "        mask_neg = (~mask).float()\n",
    "        dot_prod = torch.matmul(features, features.t())\n",
    "\n",
    "        pos_pairs_mean = (mask_pos * dot_prod).sum() / (mask_pos.sum() + 1e-6)\n",
    "        neg_pairs_mean = torch.abs(mask_neg * dot_prod).sum() / (mask_neg.sum() + 1e-6)\n",
    "\n",
    "        loss = (1.0 - pos_pairs_mean) + (0.7 * neg_pairs_mean)\n",
    "\n",
    "        return loss, pos_pairs_mean, neg_pairs_mean\n",
    "\n",
    "\n",
    "def train(train_batch, labels, model, optimizer, bce_logits_loss, opl_loss, alpha):\n",
    "    \n",
    "    average_loss = RunningAverage()\n",
    "    soft_losses = RunningAverage()\n",
    "    if opl_loss:\n",
    "        opl_losses = RunningAverage()\n",
    "\n",
    "    model.train()\n",
    "    # face_feats = torch.from_numpy(face_feats).float()\n",
    "    train_batch = torch.from_numpy(train_batch).float()\n",
    "    labels = torch.from_numpy(labels).float()\n",
    "    \n",
    "    if FLAGS.cuda:\n",
    "        train_batch, labels = train_batch.cuda(), labels.cuda()\n",
    "\n",
    "    train_batch, labels = Variable(train_batch), Variable(labels)\n",
    "    comb = model.train_forward(train_batch)\n",
    "    \n",
    "    # loss_soft = ce_loss(comb[1], labels)\n",
    "    loss_soft = bce_logits_loss(comb[1], labels)\n",
    "    predictions = sigmoid(loss_soft)\n",
    "    predictions = (predictions > 0.5).astype(int).reshape(-1)\n",
    "    \n",
    "    \n",
    "    if opl_loss:\n",
    "        loss_opl, s_fac, d_fac = opl_loss(comb[0], labels)\n",
    "        loss = loss_soft + alpha * loss_opl\n",
    "    else: \n",
    "        loss = loss_soft\n",
    "        s_fac, d_fac = 0., 0.\n",
    "        opl_losses = 0.\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    loss.backward()\n",
    "    average_loss.update(loss.item())\n",
    "    if opl_loss:\n",
    "        opl_losses.update(loss_opl.item())\n",
    "    soft_losses.update(loss_soft.item())\n",
    "    \n",
    "    optimizer.step()\n",
    "    if opl_loss:\n",
    "        return average_loss.avg(), opl_losses.avg(), soft_losses.avg(), s_fac, d_fac\n",
    "    else:\n",
    "        return average_loss.avg(), opl_losses, soft_losses.avg(), s_fac, d_fac\n",
    "\n",
    "class RunningAverage(object):\n",
    "    def __init__(self):\n",
    "        self.value_sum = 0.\n",
    "        self.num_items = 0. \n",
    "\n",
    "    def update(self, val):\n",
    "        self.value_sum += val \n",
    "        self.num_items += 1\n",
    "\n",
    "    def avg(self):\n",
    "        average = 0.\n",
    "        if self.num_items > 0:\n",
    "            average = self.value_sum / self.num_items\n",
    "\n",
    "        return average\n",
    " \n",
    "def save_checkpoint(state, directory, filename):\n",
    "    filename = os.path.join(directory, filename)\n",
    "    torch.save(state, filename)\n",
    "    "
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:39:32.491611Z",
     "start_time": "2024-07-26T12:39:31.452462Z"
    }
   },
   "cell_type": "code",
   "source": "from sklearn.metrics import precision_score",
   "id": "4fc4fb53affe6bca",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:44:00.369183Z",
     "start_time": "2024-07-26T12:44:00.360166Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# multilabel classification\n",
    "y_true = [[0, 0, 0], [1, 1, 1], [0, 1, 1]]\n",
    "y_pred = [[0, 0, 0], [1, 1, 1], [1, 1, 0]]"
   ],
   "id": "ac995f14c659bea",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:44:09.269978Z",
     "start_time": "2024-07-26T12:44:09.248748Z"
    }
   },
   "cell_type": "code",
   "source": "precision_score(y_true, y_pred, average=None)",
   "id": "265566eea7b372c3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5, 1. , 1. ])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:45:46.370449Z",
     "start_time": "2024-07-26T12:45:46.352154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "precision_score(y_true, y_pred, average='da'\n",
    "                                    )"
   ],
   "id": "31aa002ffab69971",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "average has to be one of (None, 'micro', 'macro', 'weighted', 'samples')",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-11-264ceddf7d6b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m precision_score(y_true, y_pred, average='da'\n\u001B[0m\u001B[1;32m      2\u001B[0m                                     )\n",
      "\u001B[0;32m~/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36mprecision_score\u001B[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1660\u001B[0m                                                  \u001B[0mwarn_for\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'precision'\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1661\u001B[0m                                                  \u001B[0msample_weight\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0msample_weight\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1662\u001B[0;31m                                                  zero_division=zero_division)\n\u001B[0m\u001B[1;32m   1663\u001B[0m     \u001B[0;32mreturn\u001B[0m \u001B[0mp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1664\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/utils/validation.py\u001B[0m in \u001B[0;36minner_f\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     61\u001B[0m             \u001B[0mextra_args\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m-\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mall_args\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     62\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mextra_args\u001B[0m \u001B[0;34m<=\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 63\u001B[0;31m                 \u001B[0;32mreturn\u001B[0m \u001B[0mf\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     64\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     65\u001B[0m             \u001B[0;31m# extra_args > 0\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36mprecision_recall_fscore_support\u001B[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001B[0m\n\u001B[1;32m   1463\u001B[0m         \u001B[0;32mraise\u001B[0m \u001B[0mValueError\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"beta should be >=0 in the F-beta score\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1464\u001B[0m     labels = _check_set_wise_labels(y_true, y_pred, average, labels,\n\u001B[0;32m-> 1465\u001B[0;31m                                     pos_label)\n\u001B[0m\u001B[1;32m   1466\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1467\u001B[0m     \u001B[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/miniforge3/envs/sbnet/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001B[0m in \u001B[0;36m_check_set_wise_labels\u001B[0;34m(y_true, y_pred, average, labels, pos_label)\u001B[0m\n\u001B[1;32m   1273\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0maverage\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32min\u001B[0m \u001B[0maverage_options\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0maverage\u001B[0m \u001B[0;34m!=\u001B[0m \u001B[0;34m'binary'\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1274\u001B[0m         raise ValueError('average has to be one of ' +\n\u001B[0;32m-> 1275\u001B[0;31m                          str(average_options))\n\u001B[0m\u001B[1;32m   1276\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1277\u001B[0m     \u001B[0my_type\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_check_targets\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0my_true\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0my_pred\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mValueError\u001B[0m: average has to be one of (None, 'micro', 'macro', 'weighted', 'samples')"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "7d9e30cf6e04ffbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:32.592376Z",
     "start_time": "2024-07-26T12:20:32.588734Z"
    }
   },
   "source": [
    "global FLAGS"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "d40ec09aa487851f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:33.064003Z",
     "start_time": "2024-07-26T12:20:33.048611Z"
    }
   },
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S', help='Random Seed')\n",
    "parser.add_argument('--cuda', action='store_true', default=True, help='CUDA Training')\n",
    "parser.add_argument('--save_dir', type=str, default='model', help='Directory for saving checkpoints.')\n",
    "parser.add_argument('--lr', type=float, default=1e-2, metavar='LR',\n",
    "                    help='learning rate (default: 1e-4)') \n",
    "parser.add_argument('--batch_size', type=int, default=128, help='Batch size for training.')\n",
    "parser.add_argument('--max_num_epoch', type=int, default=100, help='Max number of epochs to train, number')\n",
    "parser.add_argument('--alpha_list', type=list, default=[1], help='Alpha Values List')\n",
    "parser.add_argument('--dim_embed', type=int, default=256,\n",
    "                    help='Embedding Size')\n",
    "parser.add_argument('--split_type', type=str, default='image_only', help='split_type')"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--split_type'], dest='split_type', nargs=None, const=None, default='image_only', type=<class 'str'>, choices=None, help='split_type', metavar=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "47028af40cb5fd17",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:33.630163Z",
     "start_time": "2024-07-26T12:20:33.626445Z"
    }
   },
   "source": [
    "FLAGS, unparsed = parser.parse_known_args()"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "a22f0f44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:20:34.012786Z",
     "start_time": "2024-07-26T12:20:33.995937Z"
    }
   },
   "source": [
    "FLAGS"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(alpha_list=[1], batch_size=128, cuda=True, dim_embed=256, lr=0.01, max_num_epoch=100, save_dir='model', seed=1, split_type='image_only')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "e84b804a85f8343b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:21:16.367401Z",
     "start_time": "2024-07-26T12:20:36.101385Z"
    }
   },
   "source": [
    "train_data, train_label = read_data(FLAGS)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: image_only\n",
      "Reading Image Train\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "fd90c488685380b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:21:16.373609Z",
     "start_time": "2024-07-26T12:21:16.369294Z"
    }
   },
   "source": [
    "print('Split Type: %s'%(FLAGS.split_type))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split Type: image_only\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "id": "6561442ddc9b75bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-26T12:21:16.383462Z",
     "start_time": "2024-07-26T12:21:16.377583Z"
    }
   },
   "source": [
    "train_data.shape, train_label.shape"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15552, 7168), (15552, 27))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "fec7e50cb0caa13c",
   "metadata": {
    "scrolled": false,
    "ExecuteTime": {
     "end_time": "2024-07-26T12:21:46.479892Z",
     "start_time": "2024-07-26T12:21:34.868692Z"
    }
   },
   "source": [
    "losses = main(train_data, train_label)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marta/miniforge3/envs/sbnet/lib/python3.6/site-packages/ipykernel_launcher.py:103: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  + Number of params: 1909019\n",
      "image_only\tEpoch 001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/121 [00:00<00:12,  9.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 5/121 [00:00<00:04, 26.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 10/121 [00:00<00:03, 34.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 14/121 [00:00<00:02, 36.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 19/121 [00:00<00:02, 39.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 24/121 [00:00<00:02, 39.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 29/121 [00:00<00:02, 40.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 34/121 [00:00<00:02, 40.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 39/121 [00:01<00:01, 42.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 49/121 [00:01<00:01, 42.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 54/121 [00:01<00:01, 42.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 59/121 [00:01<00:01, 41.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 64/121 [00:01<00:01, 43.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 69/121 [00:01<00:01, 43.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 74/121 [00:01<00:01, 43.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 79/121 [00:01<00:00, 43.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 84/121 [00:02<00:00, 42.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 89/121 [00:02<00:00, 42.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 94/121 [00:02<00:00, 43.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 104/121 [00:02<00:00, 45.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 109/121 [00:02<00:00, 45.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 114/121 [00:02<00:00, 45.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:02<00:00, 42.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "image_only\tEpoch 002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/121 [00:00<00:02, 50.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 12/121 [00:00<00:02, 52.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 18/121 [00:00<00:02, 51.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 24/121 [00:00<00:01, 49.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 29/121 [00:00<00:01, 47.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 34/121 [00:00<00:01, 44.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 39/121 [00:00<00:01, 41.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▋      | 44/121 [00:00<00:01, 42.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 49/121 [00:01<00:01, 42.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▍     | 54/121 [00:01<00:01, 44.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 59/121 [00:01<00:01, 45.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 64/121 [00:01<00:01, 46.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 69/121 [00:01<00:01, 46.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 74/121 [00:01<00:01, 44.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 79/121 [00:01<00:00, 42.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 84/121 [00:01<00:00, 43.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▎  | 89/121 [00:01<00:00, 45.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 94/121 [00:02<00:00, 45.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 99/121 [00:02<00:00, 45.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 104/121 [00:02<00:00, 44.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 109/121 [00:02<00:00, 43.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 114/121 [00:02<00:00, 44.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 119/121 [00:02<00:00, 45.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 121/121 [00:02<00:00, 45.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_only\tEpoch 003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/121 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 6/121 [00:00<00:02, 52.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 12/121 [00:00<00:02, 45.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 17/121 [00:00<00:02, 42.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 22/121 [00:00<00:02, 43.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 27/121 [00:00<00:02, 41.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▋       | 32/121 [00:00<00:02, 43.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27])"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 37/121 [00:00<00:01, 42.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 42/121 [00:00<00:01, 43.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 47/121 [00:01<00:01, 43.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 52/121 [00:01<00:01, 43.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n",
      "torch.Size([128, 27]) torch.Size([128, 27])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 55/121 [00:01<00:01, 42.71it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-db369cbd71c3>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mlosses\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_data\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mtrain_label\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;32m<ipython-input-6-900de6c3f12c>\u001B[0m in \u001B[0;36mmain\u001B[0;34m(train_data, train_label)\u001B[0m\n\u001B[1;32m    163\u001B[0m                     loss_tmp, loss_opl, loss_soft, s_fac, d_fac = train(train_batch, \n\u001B[1;32m    164\u001B[0m                                                                  \u001B[0mbatch_labels\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 165\u001B[0;31m                                                                  model, optimizer, bce_logits_loss, opl_loss, alpha)\n\u001B[0m\u001B[1;32m    166\u001B[0m                     \u001B[0mloss_per_epoch\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0mloss_tmp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    167\u001B[0m                     \u001B[0ms_fac_per_epoch\u001B[0m\u001B[0;34m+=\u001B[0m\u001B[0ms_fac\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-6-900de6c3f12c>\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(train_batch, labels, model, optimizer, bce_logits_loss, opl_loss, alpha)\u001B[0m\n\u001B[1;32m    240\u001B[0m     \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    241\u001B[0m     \u001B[0;31m# face_feats = torch.from_numpy(face_feats).float()\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 242\u001B[0;31m     \u001B[0mtrain_batch\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain_batch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    243\u001B[0m     \u001B[0mlabels\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfrom_numpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfloat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    244\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "21b96f47f4532ae7"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
